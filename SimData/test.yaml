definitions:
  datasets:
    my_dataset: # user-defined dataset name
      format: AIRR
      params:
        is_repertoire: true # we are importing a repertoire dataset
        path: C:\Users\Olav\Desktop\Masteroppgave\full_sequence_simulation\airr_exporter_repertoire\exported\repertoires
        metadata_file: metadata.csv

  encodings:
    3mer:
      KmerFrequency:
        k: 3
        reads: unique
        sequence_encoding: CONTINUOUS_KMER

  ml_methods:
    k_nearest_neighbors:
      KNN:
        n_neighbors:
        - 3
        - 5
        - 7
        show_warnings: false
      model_selection_cv: true
      model_selection_n_folds: 5
    logistic_regression:
      LogisticRegression:
        C:
        - 0.01
        - 0.1
        - 1
        - 10
        - 100
        class_weight:
        - balanced
        penalty:
        - l1
        show_warnings: false
      model_selection_cv: true
      model_selection_n_folds: 5
    random_forest:
      RandomForestClassifier:
        class_weight:
        - balanced
        n_estimators:
        - 10
        - 50
        - 100
        show_warnings: false
      model_selection_cv: true
      model_selection_n_folds: 5
  reports:
    benchmark: MLSettingsPerformance
    coefficients:
      Coefficients:
        coefs_to_plot:
        - N_LARGEST
        n_largest:
        - 25
instructions:
  my_training_instruction: # user-defined instruction name
    type: TrainMLModel

    dataset: my_dataset # use the same dataset name as in definitions
    labels:
    - disease    # use a label available in the metadata.csv file

    settings: # which combinations of ML settings to run
    - encoding: 3mer
      ml_method: random_forest
    - encoding: 3mer
      ml_method: logistic_regression
    - encoding: 3mer
      ml_method: k_nearest_neighbors

    assessment: # parameters in the assessment (outer) cross-validation loop
      reports:  # plot the coefficients for the trained model
        models:
        - coefficients
      split_strategy: random   # how to split the data - here: split randomly
      split_count: 5           # how many times (here once - just to train and test)
      training_percentage: 0.7 # use 70% of the data for training

    selection: # parameters in the selection (inner) cross-validation loop
      split_strategy: random
      split_count: 1
      training_percentage: 0.7 # use all data for training

    optimization_metric: balanced_accuracy # the metric to optimize during nested cross-validation when comparing multiple models
    metrics: # other metrics to compute for reference
    - auc
    - precision
    - recall

    number_of_processes: 10 # processes for parallelization